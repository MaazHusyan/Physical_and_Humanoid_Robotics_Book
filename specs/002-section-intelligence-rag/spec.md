# Feature Specification: Section 2 - Intelligence Layer (RAG & Agent Skills)

**Feature Branch**: `002-section-intelligence-rag`
**Created**: 2026-01-02
**Status**: Draft
**Input**: User description: "Integrate Gemini 2.0 Flash via OpenAI Agent SDK, Jina Free Embeddings, Qdrant Cloud for RAG, and automate sidebars.js for robotics chapters."

## User Scenarios & Testing *(mandatory)*

### User Story 1 - Interactive Robotics Tutor (Priority: P1)

As a student reading the Kinematics chapter, I want to ask the chatbot "How do I calculate the Jacobian for a 3-DOF arm?" and receive an answer based specifically on the book's content.

**Why this priority**: Core value proposition. This transforms the book from static content to an interactive AI-native experience.

**Independent Test**: Can be tested by querying the `/api/v1/chat` endpoint with a specific topic covered in `content/docs/kinematics.md` and verifying the response contains accurate excerpts.

**Acceptance Scenarios**:

1. **Given** the Kinematics chapter is indexed in Qdrant, **When** a user asks a technical question, **Then** the system retrieves relevant context using Jina embeddings and generates a response using Gemini 2.0 Flash.
2. **Given** a non-robotics query, **When** the user asks about "cooking recipes", **Then** the agent politely refocuses the user on the book's technical subject matter.

---

### User Story 2 - Automated Knowledge Indexing (Priority: P2)

As an author adding a new chapter on "Gait Analysis", I want the system to automatically detect changes and update the vector database without manual re-indexing scripts.

**Why this priority**: Ensures longevity and ease of maintenance as the book grows.

**Independent Test**: Add a new `.md` file to `content/docs/`, run the indexing service, and verify a new collection or points appear in Qdrant Cloud.

**Acceptance Scenarios**:

1. **Given** a new markdown file in `/content/docs`, **When** the indexing task is triggered, **Then** the Jina AI model generates embeddings for each section and upserts them to Qdrant.

---

### Edge Cases

- **Rate Limiting**: System implements exponential backoff (3 attempts, 2s/4s/8s delays) when Jina AI or Gemini rate limits are hit (429 status).
- **Empty Context**: When no relevant matches exist (similarity < 0.7), Gemini provides a general robotics answer with disclaimer: "This answer is not directly from the book."
- **Token Limits**: Large chapters are split by markdown headers (H1->H2->H3) with max 1000 characters per chunk to stay within embedding limits.
- **API Quota Exhaustion**: When Gemini returns quota errors, system returns HTTP 503 with retry-after header and logs alert for admin intervention.
- **Deleted Files**: System provides `/api/v1/index/cleanup` endpoint to remove orphaned chunks when source files are deleted from `content/docs/`.

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: System MUST use **Gemini 2.0 Flash** (`gemini-2.0-flash-exp` or `gemini-2.5-flash`) via the OpenAI-compatible Agent SDK (`openai-agents` library).
- **FR-002**: System MUST use **Jina AI Free Embeddings** (`jina-embeddings-v3`) producing 1024-dimensional vectors for vectorization.
- **FR-003**: System MUST integrate with **Qdrant Cloud** as the vector storage provider using cosine similarity metric.
- **FR-004**: Backend MUST expose a streamable FastAPI endpoint for chat responses using Server-Sent Events (SSE) protocol.
- **FR-005**: Docusaurus sidebar MUST use the `autogenerated` type with `dirName: '.'` in `sidebars.js` to automatically map the physical folder structure.
- **FR-006**: System MUST handle environment variables for Cloud API keys (GEMINI_API_KEY, JINA_API_KEY, QDRANT_URL, QDRANT_API_KEY) loaded via `python-dotenv`.
- **FR-007**: System MUST split markdown content by headers (H1, H2, H3) with maximum chunk size of 1000 characters to create Knowledge Chunks.
- **FR-008**: System MUST implement exponential backoff retry logic (3 attempts, 2s initial delay) for all external API calls (Gemini, Jina, Qdrant).
- **FR-009**: System MUST preserve LaTeX formulas as-is during chunking and include them in embeddings without preprocessing.
- **FR-010**: System MUST log failed Qdrant upserts and provide a re-indexing command to recover from partial failures.

### Key Entities

- **Knowledge Chunk**: A segment of markdown text (split by headers, max 1000 chars) representing a specific robotics concept. Each chunk has a unique UUID, 1024-dim vector, chapter_id, title, and source_url in its payload. Chunks from the same header section share the same title to prevent duplication.
- **Chat Session**: A stateful interaction between a user (frontend) and the Gemini agent (backend).
- **Vector Index**: The Qdrant collection (`robotics_book_v1`) containing the book's intelligence, using cosine similarity metric and 1024-dimensional vectors.

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: Chat latency (Time to First Token) should be under 1.5 seconds.
- **SC-002**: Retrieval accuracy (Top-3) should include the relevant chapter 90% of the time for indexed topics.
- **SC-003**: 100% of chapters in `content/docs/` must be reflected in the Docusaurus sidebar.

---
ðŸ¤– Generated with [Claude Code](https://claude.com/claude-code)
